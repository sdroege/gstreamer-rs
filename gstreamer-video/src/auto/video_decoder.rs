// This file was generated by gir (https://github.com/gtk-rs/gir)
// from gir-files (https://github.com/gtk-rs/gir-files)
// DO NOT EDIT

use VideoCodecFrame;
use VideoCodecState;
use VideoFormat;
use ffi;
use glib::object::IsA;
use glib::translate::*;
use glib_ffi;
use gobject_ffi;
use gst;
use gst_ffi;
use std::mem;
use std::ptr;

glib_wrapper! {
    pub struct VideoDecoder(Object<ffi::GstVideoDecoder, ffi::GstVideoDecoderClass>): [
        gst::Element => gst_ffi::GstElement,
        gst::Object => gst_ffi::GstObject,
    ];

    match fn {
        get_type => || ffi::gst_video_decoder_get_type(),
    }
}

unsafe impl Send for VideoDecoder {}
unsafe impl Sync for VideoDecoder {}

pub trait VideoDecoderExt {
    fn add_to_frame(&self, n_bytes: i32);

    fn allocate_output_buffer(&self) -> Option<gst::Buffer>;

    fn allocate_output_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn;

    //#[cfg(any(feature = "v1_12", feature = "dox"))]
    //fn allocate_output_frame_with_params(&self, frame: &VideoCodecFrame, params: /*Ignored*/&mut gst::BufferPoolAcquireParams) -> gst::FlowReturn;

    fn drop_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn;

    fn finish_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn;

    //fn get_allocator(&self, allocator: /*Ignored*/gst::Allocator, params: /*Ignored*/gst::AllocationParams);

    //fn get_buffer_pool(&self) -> /*Ignored*/Option<gst::BufferPool>;

    fn get_estimate_rate(&self) -> i32;

    fn get_frame(&self, frame_number: i32) -> Option<VideoCodecFrame>;

    fn get_frames(&self) -> Vec<VideoCodecFrame>;

    fn get_latency(&self) -> (gst::ClockTime, gst::ClockTime);

    fn get_max_decode_time(&self, frame: &VideoCodecFrame) -> gst::ClockTimeDiff;

    fn get_max_errors(&self) -> i32;

    fn get_needs_format(&self) -> bool;

    fn get_oldest_frame(&self) -> Option<VideoCodecFrame>;

    fn get_output_state(&self) -> Option<VideoCodecState>;

    fn get_packetized(&self) -> bool;

    fn get_pending_frame_size(&self) -> usize;

    fn get_qos_proportion(&self) -> f64;

    fn have_frame(&self) -> gst::FlowReturn;

    fn merge_tags<'a, P: Into<Option<&'a gst::TagList>>>(&self, tags: P, mode: gst::TagMergeMode);

    fn negotiate(&self) -> bool;

    fn proxy_getcaps<'a, 'b, P: Into<Option<&'a gst::Caps>>, Q: Into<Option<&'b gst::Caps>>>(&self, caps: P, filter: Q) -> Option<gst::Caps>;

    fn release_frame(&self, frame: &VideoCodecFrame);

    fn set_estimate_rate(&self, enabled: bool);

    fn set_latency(&self, min_latency: gst::ClockTime, max_latency: gst::ClockTime);

    fn set_max_errors(&self, num: i32);

    fn set_needs_format(&self, enabled: bool);

    fn set_output_state<'a, P: Into<Option<&'a VideoCodecState>>>(&self, fmt: VideoFormat, width: u32, height: u32, reference: P) -> Option<VideoCodecState>;

    fn set_packetized(&self, packetized: bool);

    fn set_use_default_pad_acceptcaps(&self, use_: bool);
}

impl<O: IsA<VideoDecoder>> VideoDecoderExt for O {
    fn add_to_frame(&self, n_bytes: i32) {
        unsafe {
            ffi::gst_video_decoder_add_to_frame(self.to_glib_none().0, n_bytes);
        }
    }

    fn allocate_output_buffer(&self) -> Option<gst::Buffer> {
        unsafe {
            from_glib_full(ffi::gst_video_decoder_allocate_output_buffer(self.to_glib_none().0))
        }
    }

    fn allocate_output_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn {
        unsafe {
            from_glib(ffi::gst_video_decoder_allocate_output_frame(self.to_glib_none().0, frame.to_glib_none().0))
        }
    }

    //#[cfg(any(feature = "v1_12", feature = "dox"))]
    //fn allocate_output_frame_with_params(&self, frame: &VideoCodecFrame, params: /*Ignored*/&mut gst::BufferPoolAcquireParams) -> gst::FlowReturn {
    //    unsafe { TODO: call ffi::gst_video_decoder_allocate_output_frame_with_params() }
    //}

    fn drop_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn {
        unsafe {
            from_glib(ffi::gst_video_decoder_drop_frame(self.to_glib_none().0, frame.to_glib_full()))
        }
    }

    fn finish_frame(&self, frame: &VideoCodecFrame) -> gst::FlowReturn {
        unsafe {
            from_glib(ffi::gst_video_decoder_finish_frame(self.to_glib_none().0, frame.to_glib_full()))
        }
    }

    //fn get_allocator(&self, allocator: /*Ignored*/gst::Allocator, params: /*Ignored*/gst::AllocationParams) {
    //    unsafe { TODO: call ffi::gst_video_decoder_get_allocator() }
    //}

    //fn get_buffer_pool(&self) -> /*Ignored*/Option<gst::BufferPool> {
    //    unsafe { TODO: call ffi::gst_video_decoder_get_buffer_pool() }
    //}

    fn get_estimate_rate(&self) -> i32 {
        unsafe {
            ffi::gst_video_decoder_get_estimate_rate(self.to_glib_none().0)
        }
    }

    fn get_frame(&self, frame_number: i32) -> Option<VideoCodecFrame> {
        unsafe {
            from_glib_full(ffi::gst_video_decoder_get_frame(self.to_glib_none().0, frame_number))
        }
    }

    fn get_frames(&self) -> Vec<VideoCodecFrame> {
        unsafe {
            FromGlibPtrContainer::from_glib_full(ffi::gst_video_decoder_get_frames(self.to_glib_none().0))
        }
    }

    fn get_latency(&self) -> (gst::ClockTime, gst::ClockTime) {
        unsafe {
            let mut min_latency = mem::uninitialized();
            let mut max_latency = mem::uninitialized();
            ffi::gst_video_decoder_get_latency(self.to_glib_none().0, &mut min_latency, &mut max_latency);
            (from_glib(min_latency), from_glib(max_latency))
        }
    }

    fn get_max_decode_time(&self, frame: &VideoCodecFrame) -> gst::ClockTimeDiff {
        unsafe {
            ffi::gst_video_decoder_get_max_decode_time(self.to_glib_none().0, frame.to_glib_none().0)
        }
    }

    fn get_max_errors(&self) -> i32 {
        unsafe {
            ffi::gst_video_decoder_get_max_errors(self.to_glib_none().0)
        }
    }

    fn get_needs_format(&self) -> bool {
        unsafe {
            from_glib(ffi::gst_video_decoder_get_needs_format(self.to_glib_none().0))
        }
    }

    fn get_oldest_frame(&self) -> Option<VideoCodecFrame> {
        unsafe {
            from_glib_full(ffi::gst_video_decoder_get_oldest_frame(self.to_glib_none().0))
        }
    }

    fn get_output_state(&self) -> Option<VideoCodecState> {
        unsafe {
            from_glib_full(ffi::gst_video_decoder_get_output_state(self.to_glib_none().0))
        }
    }

    fn get_packetized(&self) -> bool {
        unsafe {
            from_glib(ffi::gst_video_decoder_get_packetized(self.to_glib_none().0))
        }
    }

    fn get_pending_frame_size(&self) -> usize {
        unsafe {
            ffi::gst_video_decoder_get_pending_frame_size(self.to_glib_none().0)
        }
    }

    fn get_qos_proportion(&self) -> f64 {
        unsafe {
            ffi::gst_video_decoder_get_qos_proportion(self.to_glib_none().0)
        }
    }

    fn have_frame(&self) -> gst::FlowReturn {
        unsafe {
            from_glib(ffi::gst_video_decoder_have_frame(self.to_glib_none().0))
        }
    }

    fn merge_tags<'a, P: Into<Option<&'a gst::TagList>>>(&self, tags: P, mode: gst::TagMergeMode) {
        let tags = tags.into();
        let tags = tags.to_glib_none();
        unsafe {
            ffi::gst_video_decoder_merge_tags(self.to_glib_none().0, tags.0, mode.to_glib());
        }
    }

    fn negotiate(&self) -> bool {
        unsafe {
            from_glib(ffi::gst_video_decoder_negotiate(self.to_glib_none().0))
        }
    }

    fn proxy_getcaps<'a, 'b, P: Into<Option<&'a gst::Caps>>, Q: Into<Option<&'b gst::Caps>>>(&self, caps: P, filter: Q) -> Option<gst::Caps> {
        let caps = caps.into();
        let caps = caps.to_glib_none();
        let filter = filter.into();
        let filter = filter.to_glib_none();
        unsafe {
            from_glib_full(ffi::gst_video_decoder_proxy_getcaps(self.to_glib_none().0, caps.0, filter.0))
        }
    }

    fn release_frame(&self, frame: &VideoCodecFrame) {
        unsafe {
            ffi::gst_video_decoder_release_frame(self.to_glib_none().0, frame.to_glib_full());
        }
    }

    fn set_estimate_rate(&self, enabled: bool) {
        unsafe {
            ffi::gst_video_decoder_set_estimate_rate(self.to_glib_none().0, enabled.to_glib());
        }
    }

    fn set_latency(&self, min_latency: gst::ClockTime, max_latency: gst::ClockTime) {
        unsafe {
            ffi::gst_video_decoder_set_latency(self.to_glib_none().0, min_latency.to_glib(), max_latency.to_glib());
        }
    }

    fn set_max_errors(&self, num: i32) {
        unsafe {
            ffi::gst_video_decoder_set_max_errors(self.to_glib_none().0, num);
        }
    }

    fn set_needs_format(&self, enabled: bool) {
        unsafe {
            ffi::gst_video_decoder_set_needs_format(self.to_glib_none().0, enabled.to_glib());
        }
    }

    fn set_output_state<'a, P: Into<Option<&'a VideoCodecState>>>(&self, fmt: VideoFormat, width: u32, height: u32, reference: P) -> Option<VideoCodecState> {
        let reference = reference.into();
        let reference = reference.to_glib_none();
        unsafe {
            from_glib_full(ffi::gst_video_decoder_set_output_state(self.to_glib_none().0, fmt.to_glib(), width, height, reference.0))
        }
    }

    fn set_packetized(&self, packetized: bool) {
        unsafe {
            ffi::gst_video_decoder_set_packetized(self.to_glib_none().0, packetized.to_glib());
        }
    }

    fn set_use_default_pad_acceptcaps(&self, use_: bool) {
        unsafe {
            ffi::gst_video_decoder_set_use_default_pad_acceptcaps(self.to_glib_none().0, use_.to_glib());
        }
    }
}
